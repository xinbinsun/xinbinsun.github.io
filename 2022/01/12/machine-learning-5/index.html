<!DOCTYPE html>
<html lang="Chinese/English">
    <head>
  <!-- 元数据 -->
  <meta charset="utf-8">
  <link rel="icon" href="/images/avatar.webp">
  
  <title>MINIST手写数字识别：分类应用入门 | Neo Sun</title>
  <meta name="author" content="孙新斌" />
  <meta http-equiv="Cache-Control" content="no-transform" />
  <meta http-equiv="Cache-Control" content="no-siteapp" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <meta name="robots" content="index,follow" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <meta name="format-detection" content="telphone=no, email=no" />
  
    <meta name="keywords" content="DL" />
  
  <meta name="description" content="用神经元处理分类问题">
<meta property="og:type" content="article">
<meta property="og:title" content="MINIST手写数字识别：分类应用入门">
<meta property="og:url" content="http://sunxinbin.cn/2022/01/12/machine-learning-5/index.html">
<meta property="og:site_name" content="Neo Sun">
<meta property="og:description" content="用神经元处理分类问题">
<meta property="og:locale">
<meta property="og:image" content="http://sunxinbin.cn/images/avatar.webp">
<meta property="article:published_time" content="2022-01-12T12:00:00.000Z">
<meta property="article:modified_time" content="2023-03-30T11:26:48.945Z">
<meta property="article:author" content="孙新斌">
<meta property="article:tag" content="DL">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://sunxinbin.cn/images/avatar.webp">
  
  <!-- 站点验证相关 -->
  
    
    
    
  
  <!-- 样式表文件 -->
  <link rel="stylesheet" id="kratos-css" href="/css/kratosr.min.css" media="all"></script>
  
    <link rel="stylesheet" id="darkmode-css" href="/css/kr-color-dark.min.css" media="(prefers-color-scheme: dark)"></script>
    <script src="/js/kr-dark.min.js"></script>
  
  
    <link rel="stylesheet" id="highlight-css" href="/css/highlight/night-eighties.min.css" media="all"></script>
  
  <link rel="stylesheet" id="fontawe-css" href="/vendors/font-awesome@4.7.0/css/font-awesome.min.css" media="all"></script>
  <link rel="stylesheet" id="nprogress-css" href="/vendors/nprogress@0.2.0/nprogress.css" media="all"></script>
  
  
  
    <link rel="stylesheet" href="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.css"></script>
  
  <!-- 不得不预先加载的一些JS文件 -->
  <script src="/vendors/jquery@3.6.0/dist/jquery.min.js"></script>
  
    <script src="/vendors/qrcode_js@1.0.0/qrcode.min.js"></script>
  
  
  <style>
    
      .kratos-cover.kratos-cover-2 {
        background-image: url('/images/banner.webp');
      }
    
    
      @media(min-width:768px) {
        body.custom-background {
          background-image: url('/images/bg.webp');
        }
      }
    
  </style>
  
<meta name="generator" content="Hexo 6.2.0"></head>


    <body class="custom-background">
        <div id="kratos-wrapper">
    <div id="kratos-page">
        <div id="kratos-header">
            <header id="kratos-desktop-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="nav-header">
                        <nav id="kratos-menu-wrap">
                            <ul id="kratos-primary-menu" class="sf-menu">
                                
                                    
                                    
                                        
                                            <li><a href="/"><i class="fa fa-home"></i>Home</a></li>
                                        
                                    
                                        
                                            <li><a href="/archives/"><i class="fa fa-file"></i>Archives</a></li>
                                        
                                    
                                        
                                            <li><a href="/friends/"><i class="fa fa-paw"></i>Search Engine</a></li>
                                        
                                    
                                        
                                            <li>
                                                <a><i class="fa fa-link"></i>About</a>
                                                <ul class="sub-menu">
                                                    
                                                        
                                                    
                                                        
                                                            <li><a href="https://sunxinbin.cn">Blog</a></li>
                                                        
                                                    
                                                        
                                                            <li><a target="_blank" rel="noopener" href="https://github.com/xinbinsun">Github</a></li>
                                                        
                                                    
                                                </ul>
                                            </li>
                                        
                                    
                                
                            </ul>
                        </nav>
                    </div>
                </div>
            </header>
            <header id="kratos-mobile-topnav" class="kratos-topnav">
                <div class="container">
                    <div class="color-logo"><a href="/">Neo Sun</a></div>
                    <div class="nav-toggle">
                        <a class="kratos-nav-toggle js-kratos-nav-toggle">
                            <i></i>
                        </a>
                    </div>
                </div>
            </header>
        </div>
        <div class="kratos-start kratos-hero-2">
            <!-- <div class="kratos-overlay"></div> -->
            <div class="kratos-cover kratos-cover-2 text-center">
                <div class="desc desc2 animate-box">
                    <a href="/">
                        <h2>Neo Sun</h2> <br />
                        <span>What&#39;s past is prologue</span>
                    </a>
                </div>
            </div>
        </div>

        <div id="kratos-blog-post">
            <div class="container">
                <div id="main" class="row">
                    

        

            <section class="col-md-8">

        

            <article itemscope itemtype="https://schema.org/Article">
    
    <link itemprop="mainEntityOfPage" href="http://sunxinbin.cn/2022/01/12/machine-learning-5/">
    <div class="kratos-hentry kratos-post-inner clearfix">
        <header class="kratos-entry-header">
            
                <h1 class="kratos-entry-title text-center" itemprop="name headline">MINIST手写数字识别：分类应用入门</h1>
            
            
            <ul class="kratos-post-meta text-center">
                <li><time datetime="2022-01-12T12:00:00.000Z" itemprop="datePublished"><i class="fa fa-calendar"></i> 2022-01-12</time></li>
                <li itemprop="author" itemscope itemtype="https://schema.org/Person">
                    <i class="fa fa-user"></i> Author <span itemprop="name">孙新斌</span>
                </li>
                <li>
                    <i class="fa fa-edit"></i> 
                    
                    
                        ~31.25K
                    
                    words
                </li>
                
            </ul>
        </header>
        <div class="kratos-post-content">
            
            <div id="expire-alert" class="alert alert-warning hidden" role="alert">
                <div class="icon"><i class="fa fa-warning"></i></div>
                <div class="text"><p>This article has been edited <time datetime="1680175608945"></time> ago, and some of its content might need to be updated.</p></div>
            </div>
            
            
            
                <div class="kratos-post-inner-toc toc-div-class" >
                    <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E9%97%AE%E9%A2%98"><span class="toc-number">1.</span> <span class="toc-text">MNIST手写数字识别问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-number">1.1.</span> <span class="toc-text">分类问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%BB%E5%8F%96%E6%96%B9%E6%B3%95"><span class="toc-number">1.2.</span> <span class="toc-text">数据集读取方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81"><span class="toc-number">1.3.</span> <span class="toc-text">独热编码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86"><span class="toc-number">1.4.</span> <span class="toc-text">数据集划分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-number">1.5.</span> <span class="toc-text">逻辑回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E5%88%86%E7%B1%BB"><span class="toc-number">1.6.</span> <span class="toc-text">多元分类</span></a></li></ol></li></ol>
                </div>
            
            <hr />
            <div itemprop="articleBody"><p><strong>用神经元处理分类问题</strong><br><span id="more"></span></p>
<h1 id="MNIST手写数字识别问题"><a href="#MNIST手写数字识别问题" class="headerlink" title="MNIST手写数字识别问题"></a>MNIST手写数字识别问题</h1><h2 id="分类问题"><a href="#分类问题" class="headerlink" title="分类问题"></a>分类问题</h2><p><strong>MNIST手写数字识别数据集</strong><br><strong>MNIST 数据集</strong>来自美国国家标准与技术研究所, National Institute of Standards and Technology (NIST).<br>数据集由来自 250 个不同人手写的数字构成, 其中 50% 是高中学生, 50% 来自人口普查局 (the Census Bureau) 的工作人员<br>训练集 55000 验证集 5000 测试集 10000</p>
<h2 id="数据集读取方法"><a href="#数据集读取方法" class="headerlink" title="数据集读取方法"></a>数据集读取方法</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data <span class="keyword">as</span> input_data</span><br><span class="line"><span class="comment">#10分类采用One Hot编码</span></span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&quot;MNIST_data/&quot;</span>, one_hot=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<p><strong>了解数据集</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;训练集train数量：&#x27;</span>,mnist.train.num_examples,</span><br><span class="line">     <span class="string">&#x27;,验证集validation数量：&#x27;</span>,mnist.validation.num_examples,</span><br><span class="line">     <span class="string">&#x27;,测试集test数量：&#x27;</span>,mnist.test.num_examples)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;train images shape:&#x27;</span>,mnist.train.images.shape,</span><br><span class="line">     <span class="string">&#x27;labels shape:&#x27;</span>,mnist.train.labels.shape)</span><br><span class="line"></span><br><span class="line"><span class="built_in">len</span>(mnist.train.images[<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">mnist.train.images[<span class="number">0</span>].shape</span><br><span class="line"></span><br><span class="line"><span class="comment">#Image数据再塑形reshape</span></span><br><span class="line">mnist.train.images[<span class="number">0</span>].reshape(<span class="number">28</span>,<span class="number">28</span>)</span><br><span class="line"></span><br></pre></td></tr></table></figure></p>
<p><strong>可视化image</strong><br>plt.imshow()第二个参数是这个图像的模式参数，“binary”表示以灰度模式显示。<br>plt.imshow()函数中的图像数据参数支持一下数据形状：<br>•（M，N） ：二维数值，代表图像大小为M行N列，值为每个像素点的取值。<br>•（M，N，3） ：三维度数值，代表图像大小为M行N列（即图片的高和宽），每个像素点的取值具有RGB三个通道的值（float或uint8）。<br>• 参数cmap缺省值为none，将把图像数据映射为彩色图显示<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_image</span>(<span class="params">image</span>):</span><br><span class="line">    plt.imshow(image.reshape(<span class="number">28</span>,<span class="number">28</span>),cmap=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p>
<h2 id="独热编码"><a href="#独热编码" class="headerlink" title="独热编码"></a>独热编码</h2><p>一种<strong>稀疏向量</strong>，其中：<strong>一个元素设为 1，所有其他元素均设为 0</strong><br>独热编码常用于表示拥有<strong>有限个可能值</strong>的字符串或标识符<br>例如：假设某个植物学数据集记录了 15000 个不同的物种，其中每个物种都用独一无二的字符串标识符来表示。在特征工程过程中，可能需要将这些字符串标识符编码为独热向量，向量的大小为 15000<br><strong>使用独热编码的原因</strong><br>1 将离散特征的取值扩展到了欧式空间，离散特征的某个取值就对应欧式空间的某个点<br>2 机器学习算法中，特征之间距离的计算或相似度的常用计算方法都是基于欧式空间的<br>3 将离散型特征使用one-hot编码，会让特征之间的距离计算更加合理</p>
<h2 id="数据集划分"><a href="#数据集划分" class="headerlink" title="数据集划分"></a>数据集划分</h2><p>构建和训练机器学习模型是希望对新的数据做出良好预测<br>如何去保证训练的实效，可以应对以前未见过的数据呢？<br>一种方法是将数据集分成两个子集：<br><strong>训练集</strong> - 用于训练模型的子集<br><strong>测试集</strong> - 用于测试模型的子集<br>通常，在<strong>测试集</strong>上表现是否良好是衡量能否在新数据上表现良好的有用指标，前提是：<br><strong>测试集足够大</strong><br><strong>不会反复使用相同的测试集来作假</strong></p>
<p><strong>拆分数据</strong><br>将单个数据集拆分为一个<strong>训练集</strong>和一个<strong>测试集</strong><br>确保测试集满足以下两个条件：<br><strong>规模足够大</strong>，可产生具有统计意义的结果<br><strong>能代表整个数据集</strong>，测试集的特征应该与训练集的特征相同</p>
<p><strong>工作流程</strong><br><img src="/2022/01/12/machine-learning-5/pic2.png" alt="work"></p>
<p><strong>问题：多次重复执行该流程可能导致模型不知不觉地拟合了特定测试集的特性</strong></p>
<p><strong>新的工作流程</strong><br><img src="/2022/01/12/machine-learning-5/pic3.png" alt="new work"><br><strong>前向计算与结果分类</strong><br><img src="/2022/01/12/machine-learning-5/pic4.png" alt="softmax"></p>
<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p>许多问题的预测结果是一个在连续空间的数值，比如房价预测问题，可以用线性模型来描述<br>但也有很多场景需要输出的是<strong>概率估算值</strong>，例如：<br>• 根据邮件内容判断是垃圾邮件的可能性<br>• 根据医学影像判断肿瘤是恶性的可能性<br>• 手写数字分别是 0、1、2、3、4、5、6、7、8、9的可能性（概率）<br>这时需要将预测输出值控制在 [0，1]区间内<br><strong>二元分类问题</strong>的目标是正确预测两个可能的标签中的一个<br><strong>逻辑回归</strong>（Logistic Regression）可以用于处理这类问题<br><strong>Sigmod函数</strong><br><img src="/2022/01/12/machine-learning-5/pic5.png" alt="sigmod"><br><strong>逻辑回归中的损失函数</strong><br><img src="/2022/01/12/machine-learning-5/pic6.png" alt="损失函数"></p>
<h2 id="多元分类"><a href="#多元分类" class="headerlink" title="多元分类"></a>多元分类</h2><p><strong>Softmax 思想</strong><br><strong>逻辑回归</strong>可生成介于 0 和 1.0 之间的小数。<br>例如，某电子邮件分类器的逻辑回归输出值为 0.8，表明电子邮件是垃圾邮件的概率为80%，不是垃圾邮件的概率为 20%。很明显，一封电子邮件是垃圾邮件或非垃圾邮件的概率之和为 1.0。<br><strong>Softmax</strong>将这一想法延伸到多类别领域。<br>在多类别问题中，Softmax会为每个类别分配一个用小数表示的概率。这些用小数表示的概率相加之和必须是 1.0。<br><img src="/2022/01/12/machine-learning-5/pic7.png" alt="softmax方程式"><br><strong>交叉熵损失函数</strong><br>交叉熵是一个信息论中的概念，它原来是用来估算平均编码长度的。给定两个概率分布p和q，通过q来表示p的交叉熵为<br><img src="/2022/01/12/machine-learning-5/pic8.png" alt="交叉熵"><br><strong>交叉熵</strong>刻画的是<strong>两个概率分布之间的距离</strong>，p代表正确答案，q代表的是预测值，交叉熵越小，两个概率的分布约接近<br><strong>完整程序</strong><br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">import</span> tensorflow.examples.tutorials.mnist.input_data <span class="keyword">as</span> input_data</span><br><span class="line">mnist = input_data.read_data_sets(<span class="string">&quot;MNIST_data/&quot;</span>, one_hot=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_image</span>(<span class="params">image</span>):</span><br><span class="line">    plt.imshow(image.reshape(<span class="number">28</span>,<span class="number">28</span>),cmap=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义带输入数据的占位符</span></span><br><span class="line"><span class="comment">#784个像素点</span></span><br><span class="line">x = tf.placeholder(tf.float32,[<span class="literal">None</span>, <span class="number">784</span>], name=<span class="string">&quot;X&quot;</span>)</span><br><span class="line"><span class="comment">#10个类别</span></span><br><span class="line">y = tf.placeholder(tf.float32,[<span class="literal">None</span>,<span class="number">10</span>], name=<span class="string">&quot;Y&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义模型变量</span></span><br><span class="line"><span class="comment">#正态分布随机数初始化权重w，常数0初始化偏置b</span></span><br><span class="line">W = tf.Variable(tf.random_normal([<span class="number">784</span>, <span class="number">10</span>]), name=<span class="string">&quot;W&quot;</span>)</span><br><span class="line">b = tf.Variable(tf.zeros([<span class="number">10</span>]),name=<span class="string">&quot;b&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义前向计算</span></span><br><span class="line">forward = tf.matmul(x,W) + b</span><br><span class="line"></span><br><span class="line"><span class="comment">#结果分类（采用softmax分类）</span></span><br><span class="line">pred = tf.nn.softmax(forward)</span><br><span class="line"></span><br><span class="line">train_epochs = <span class="number">500</span></span><br><span class="line">batch_size = <span class="number">100</span></span><br><span class="line">total_batch = <span class="built_in">int</span>(mnist.train.num_examples/batch_size)</span><br><span class="line">display_step = <span class="number">1</span></span><br><span class="line">learning_rate = <span class="number">0.01</span></span><br><span class="line"></span><br><span class="line"><span class="comment">#交叉熵</span></span><br><span class="line">loss_function = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred),</span><br><span class="line">                            reduction_indices=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#选择优化器                                   </span></span><br><span class="line">optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss_function)</span><br><span class="line"></span><br><span class="line"><span class="comment">#检查预测类别与实际类别的匹配情况</span></span><br><span class="line">correct_prediction = tf.equal(tf.argmax(pred,<span class="number">1</span>),tf.argmax(y,<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line"><span class="comment">#准确率</span></span><br><span class="line">accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))</span><br><span class="line"></span><br><span class="line"><span class="comment">#声明会话，初始化变量</span></span><br><span class="line">sess = tf.Session()</span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">sess.run(init)</span><br><span class="line"></span><br><span class="line"><span class="comment">#开始训练</span></span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span> (train_epochs):</span><br><span class="line">    <span class="keyword">for</span> batch <span class="keyword">in</span> <span class="built_in">range</span>(total_batch):</span><br><span class="line">        xs,ys = mnist.train.next_batch(batch_size)<span class="comment">#读取批次数据</span></span><br><span class="line">        sess.run(optimizer,feed_dict=&#123;x:xs,y:ys&#125;)<span class="comment">#执行训练</span></span><br><span class="line">    <span class="comment">#验证数据计算误差与准确率</span></span><br><span class="line">    loss,acc = sess.run([loss_function,accuracy],</span><br><span class="line">                       feed_dict=&#123;x:mnist.validation.images,y:mnist.validation.labels&#125;)</span><br><span class="line">    <span class="comment">#打印详细信息</span></span><br><span class="line">    <span class="keyword">if</span>(epoch+<span class="number">1</span>) % display_step == <span class="number">0</span>:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&quot;Train Epoch:&quot;</span>,<span class="string">&#x27;%02d&#x27;</span> % (epoch+<span class="number">1</span>),<span class="string">&quot;Loss=&quot;</span>,<span class="string">&quot;&#123;:.9f&#125;&quot;</span>.<span class="built_in">format</span>(loss),\</span><br><span class="line">             <span class="string">&quot;Accuracy=&quot;</span>,<span class="string">&quot;&#123;:.4f&#125;&quot;</span>.<span class="built_in">format</span>(acc))</span><br><span class="line">        </span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Train Finshied!&quot;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment">#评估模型</span></span><br><span class="line">accu_test = sess.run(accuracy,</span><br><span class="line">                    feed_dict=&#123;x:mnist.test.images,y:mnist.test.labels&#125;)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Test Accurary:&quot;</span>,accu_test)</span><br><span class="line"></span><br><span class="line"><span class="comment">#应用模型</span></span><br><span class="line">prediction_result = sess.run(tf.argmax(pred,<span class="number">1</span>),</span><br><span class="line">                            feed_dict = &#123;x:mnist.test.images&#125;)</span><br><span class="line"></span><br><span class="line"><span class="comment">#查看预测结果</span></span><br><span class="line">prediction_result[<span class="number">0</span>:<span class="number">10</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义可视化函数</span></span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plot</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">plot_images_labels_prediction</span>(<span class="params">images,</span></span><br><span class="line"><span class="params">                                 labels,</span></span><br><span class="line"><span class="params">                                 prediction,</span></span><br><span class="line"><span class="params">                                 index,</span></span><br><span class="line"><span class="params">                                 num=<span class="number">10</span></span>):</span><br><span class="line">    fig = plt.gcf()</span><br><span class="line">    fig.set_size_inches(<span class="number">10</span>, <span class="number">12</span>)</span><br><span class="line">    <span class="keyword">if</span> num &gt; <span class="number">25</span> :</span><br><span class="line">        num = <span class="number">25</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,num):</span><br><span class="line">        ax = plt.subplot(<span class="number">5</span>,<span class="number">5</span>,i+<span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">        ax.imshow(np.reshape(images[index],(<span class="number">28</span>,<span class="number">28</span>)),</span><br><span class="line">                 cmap=<span class="string">&#x27;binary&#x27;</span>)</span><br><span class="line">        </span><br><span class="line">        title = <span class="string">&quot;label=&quot;</span> + <span class="built_in">str</span>(np.argmax(labels[index]))</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(prediction)&gt;<span class="number">0</span>:</span><br><span class="line">            title += <span class="string">&quot;,predict=&quot;</span> + <span class="built_in">str</span>(prediction[index])</span><br><span class="line">            </span><br><span class="line">        ax.set_title(title,fontsize=<span class="number">10</span>)</span><br><span class="line">        ax.set_xticks([]);</span><br><span class="line">        ax.set_yticks([])</span><br><span class="line">        index += <span class="number">1</span></span><br><span class="line">    plt.show()</span><br><span class="line"></span><br><span class="line"><span class="comment">#可视化预测结果</span></span><br><span class="line">plot_images_labels_prediction(mnist.test.images,</span><br><span class="line">                             mnist.test.labels,</span><br><span class="line">                             prediction_result,<span class="number">10</span>,<span class="number">15</span>)</span><br></pre></td></tr></table></figure></p>
<p><strong>训练结果如下显示：（多数据警告）</strong><br><div class="xControl">
    <div class="xHeading"><div class="xIcon"><i class="fa fa-plus"></i></div><span>训练结果</span></div>
    <div class="xContent"><div class="inner">
        <p>Train Epoch: 01 Loss= 6.405103683 Accuracy= 0.2280<br>Train Epoch: 02 Loss= 3.764361620 Accuracy= 0.4148<br>Train Epoch: 03 Loss= 2.728085279 Accuracy= 0.5380<br>Train Epoch: 04 Loss= 2.206749916 Accuracy= 0.6040<br>Train Epoch: 05 Loss= 1.891477942 Accuracy= 0.6544<br>Train Epoch: 06 Loss= 1.679210782 Accuracy= 0.6842<br>Train Epoch: 07 Loss= 1.525882602 Accuracy= 0.7104<br>Train Epoch: 08 Loss= 1.408041358 Accuracy= 0.7276<br>Train Epoch: 09 Loss= 1.315110087 Accuracy= 0.7408<br>Train Epoch: 10 Loss= 1.239514709 Accuracy= 0.7536<br>Train Epoch: 11 Loss= 1.177493334 Accuracy= 0.7648<br>Train Epoch: 12 Loss= 1.123586535 Accuracy= 0.7726<br>Train Epoch: 13 Loss= 1.077311754 Accuracy= 0.7818<br>Train Epoch: 14 Loss= 1.036843181 Accuracy= 0.7892<br>Train Epoch: 15 Loss= 1.002879262 Accuracy= 0.7950<br>Train Epoch: 16 Loss= 0.971034110 Accuracy= 0.8008<br>Train Epoch: 17 Loss= 0.943259358 Accuracy= 0.8056<br>Train Epoch: 18 Loss= 0.917949319 Accuracy= 0.8094<br>Train Epoch: 19 Loss= 0.894973814 Accuracy= 0.8132<br>Train Epoch: 20 Loss= 0.874269903 Accuracy= 0.8188<br>Train Epoch: 21 Loss= 0.854999602 Accuracy= 0.8222<br>Train Epoch: 22 Loss= 0.837613404 Accuracy= 0.8258<br>Train Epoch: 23 Loss= 0.821559370 Accuracy= 0.8272<br>Train Epoch: 24 Loss= 0.807139874 Accuracy= 0.8294<br>Train Epoch: 25 Loss= 0.792462468 Accuracy= 0.8322<br>Train Epoch: 26 Loss= 0.779907167 Accuracy= 0.8336<br>Train Epoch: 27 Loss= 0.767695904 Accuracy= 0.8372<br>Train Epoch: 28 Loss= 0.756269753 Accuracy= 0.8376<br>Train Epoch: 29 Loss= 0.745229483 Accuracy= 0.8398<br>Train Epoch: 30 Loss= 0.735225081 Accuracy= 0.8424<br>Train Epoch: 31 Loss= 0.725513577 Accuracy= 0.8442<br>Train Epoch: 32 Loss= 0.716079116 Accuracy= 0.8466<br>Train Epoch: 33 Loss= 0.708266139 Accuracy= 0.8472<br>Train Epoch: 34 Loss= 0.700395644 Accuracy= 0.8482<br>Train Epoch: 35 Loss= 0.692030370 Accuracy= 0.8500<br>Train Epoch: 36 Loss= 0.684325218 Accuracy= 0.8524<br>Train Epoch: 37 Loss= 0.677517653 Accuracy= 0.8520<br>Train Epoch: 38 Loss= 0.671082914 Accuracy= 0.8536<br>Train Epoch: 39 Loss= 0.664354265 Accuracy= 0.8546<br>Train Epoch: 40 Loss= 0.658523440 Accuracy= 0.8554<br>Train Epoch: 41 Loss= 0.652254462 Accuracy= 0.8562<br>Train Epoch: 42 Loss= 0.646569550 Accuracy= 0.8564<br>Train Epoch: 43 Loss= 0.640967071 Accuracy= 0.8562<br>Train Epoch: 44 Loss= 0.635610282 Accuracy= 0.8568<br>Train Epoch: 45 Loss= 0.630128682 Accuracy= 0.8588<br>Train Epoch: 46 Loss= 0.625474632 Accuracy= 0.8600<br>Train Epoch: 47 Loss= 0.620498955 Accuracy= 0.8608<br>Train Epoch: 48 Loss= 0.616365254 Accuracy= 0.8608<br>Train Epoch: 49 Loss= 0.612295687 Accuracy= 0.8622<br>Train Epoch: 50 Loss= 0.607778609 Accuracy= 0.8626<br>Train Epoch: 51 Loss= 0.603170395 Accuracy= 0.8644<br>Train Epoch: 52 Loss= 0.599933922 Accuracy= 0.8648<br>Train Epoch: 53 Loss= 0.595565438 Accuracy= 0.8670<br>Train Epoch: 54 Loss= 0.591758490 Accuracy= 0.8680<br>Train Epoch: 55 Loss= 0.588303804 Accuracy= 0.8694<br>Train Epoch: 56 Loss= 0.585322618 Accuracy= 0.8696<br>Train Epoch: 57 Loss= 0.581881523 Accuracy= 0.8698<br>Train Epoch: 58 Loss= 0.577679873 Accuracy= 0.8706<br>Train Epoch: 59 Loss= 0.574802935 Accuracy= 0.8716<br>Train Epoch: 60 Loss= 0.572479665 Accuracy= 0.8724<br>Train Epoch: 61 Loss= 0.568615794 Accuracy= 0.8730<br>Train Epoch: 62 Loss= 0.566718578 Accuracy= 0.8728<br>Train Epoch: 63 Loss= 0.563213229 Accuracy= 0.8730<br>Train Epoch: 64 Loss= 0.559740126 Accuracy= 0.8732<br>Train Epoch: 65 Loss= 0.556897581 Accuracy= 0.8732<br>Train Epoch: 66 Loss= 0.554247439 Accuracy= 0.8750<br>Train Epoch: 67 Loss= 0.551319838 Accuracy= 0.8754<br>Train Epoch: 68 Loss= 0.548921108 Accuracy= 0.8742<br>Train Epoch: 69 Loss= 0.546500266 Accuracy= 0.8752<br>Train Epoch: 70 Loss= 0.543983519 Accuracy= 0.8758<br>Train Epoch: 71 Loss= 0.542061985 Accuracy= 0.8758<br>Train Epoch: 72 Loss= 0.539074361 Accuracy= 0.8768<br>Train Epoch: 73 Loss= 0.536839545 Accuracy= 0.8766<br>Train Epoch: 74 Loss= 0.534821987 Accuracy= 0.8764<br>Train Epoch: 75 Loss= 0.533168137 Accuracy= 0.8774<br>Train Epoch: 76 Loss= 0.530308068 Accuracy= 0.8784<br>Train Epoch: 77 Loss= 0.528434753 Accuracy= 0.8778<br>Train Epoch: 78 Loss= 0.526309192 Accuracy= 0.8788<br>Train Epoch: 79 Loss= 0.524245977 Accuracy= 0.8782<br>Train Epoch: 80 Loss= 0.522068501 Accuracy= 0.8792<br>Train Epoch: 81 Loss= 0.520250797 Accuracy= 0.8794<br>Train Epoch: 82 Loss= 0.517979860 Accuracy= 0.8794<br>Train Epoch: 83 Loss= 0.516227961 Accuracy= 0.8806<br>Train Epoch: 84 Loss= 0.514664233 Accuracy= 0.8802<br>Train Epoch: 85 Loss= 0.512204289 Accuracy= 0.8802<br>Train Epoch: 86 Loss= 0.510789692 Accuracy= 0.8814<br>Train Epoch: 87 Loss= 0.509589970 Accuracy= 0.8810<br>Train Epoch: 88 Loss= 0.507072687 Accuracy= 0.8816<br>Train Epoch: 89 Loss= 0.505876541 Accuracy= 0.8824<br>Train Epoch: 90 Loss= 0.504153013 Accuracy= 0.8822<br>Train Epoch: 91 Loss= 0.502235591 Accuracy= 0.8832<br>Train Epoch: 92 Loss= 0.501242876 Accuracy= 0.8828<br>Train Epoch: 93 Loss= 0.498941988 Accuracy= 0.8836<br>Train Epoch: 94 Loss= 0.497406751 Accuracy= 0.8832<br>Train Epoch: 95 Loss= 0.496222556 Accuracy= 0.8838<br>Train Epoch: 96 Loss= 0.494214565 Accuracy= 0.8840<br>Train Epoch: 97 Loss= 0.493356436 Accuracy= 0.8832<br>Train Epoch: 98 Loss= 0.491570175 Accuracy= 0.8846<br>Train Epoch: 99 Loss= 0.489944965 Accuracy= 0.8840<br>Train Epoch: 100 Loss= 0.488946378 Accuracy= 0.8842<br>Train Epoch: 101 Loss= 0.487533092 Accuracy= 0.8844<br>Train Epoch: 102 Loss= 0.485964954 Accuracy= 0.8852<br>Train Epoch: 103 Loss= 0.484404892 Accuracy= 0.8852<br>Train Epoch: 104 Loss= 0.483356357 Accuracy= 0.8846<br>Train Epoch: 105 Loss= 0.482004821 Accuracy= 0.8860<br>Train Epoch: 106 Loss= 0.480790615 Accuracy= 0.8854<br>Train Epoch: 107 Loss= 0.479260147 Accuracy= 0.8858<br>Train Epoch: 108 Loss= 0.478474498 Accuracy= 0.8860<br>Train Epoch: 109 Loss= 0.476907611 Accuracy= 0.8862<br>Train Epoch: 110 Loss= 0.475418597 Accuracy= 0.8868<br>Train Epoch: 111 Loss= 0.474131107 Accuracy= 0.8870<br>Train Epoch: 112 Loss= 0.473437607 Accuracy= 0.8874<br>Train Epoch: 113 Loss= 0.471899986 Accuracy= 0.8874<br>Train Epoch: 114 Loss= 0.470724523 Accuracy= 0.8882<br>Train Epoch: 115 Loss= 0.469866693 Accuracy= 0.8880<br>Train Epoch: 116 Loss= 0.468689829 Accuracy= 0.8872<br>Train Epoch: 117 Loss= 0.468155473 Accuracy= 0.8878<br>Train Epoch: 118 Loss= 0.466815442 Accuracy= 0.8886<br>Train Epoch: 119 Loss= 0.465229392 Accuracy= 0.8882<br>Train Epoch: 120 Loss= 0.464131504 Accuracy= 0.8890<br>Train Epoch: 121 Loss= 0.462855667 Accuracy= 0.8886<br>Train Epoch: 122 Loss= 0.462298840 Accuracy= 0.8880<br>Train Epoch: 123 Loss= 0.461265326 Accuracy= 0.8894<br>Train Epoch: 124 Loss= 0.460113525 Accuracy= 0.8894<br>Train Epoch: 125 Loss= 0.459472865 Accuracy= 0.8892<br>Train Epoch: 126 Loss= 0.458169192 Accuracy= 0.8894<br>Train Epoch: 127 Loss= 0.456787854 Accuracy= 0.8898<br>Train Epoch: 128 Loss= 0.456247598 Accuracy= 0.8892<br>Train Epoch: 129 Loss= 0.455326319 Accuracy= 0.8898<br>Train Epoch: 130 Loss= 0.453999221 Accuracy= 0.8904<br>Train Epoch: 131 Loss= 0.453291893 Accuracy= 0.8900<br>Train Epoch: 132 Loss= 0.452165246 Accuracy= 0.8900<br>Train Epoch: 133 Loss= 0.451443315 Accuracy= 0.8906<br>Train Epoch: 134 Loss= 0.450718075 Accuracy= 0.8898<br>Train Epoch: 135 Loss= 0.449742883 Accuracy= 0.8906<br>Train Epoch: 136 Loss= 0.448562503 Accuracy= 0.8908<br>Train Epoch: 137 Loss= 0.447787493 Accuracy= 0.8912<br>Train Epoch: 138 Loss= 0.447070807 Accuracy= 0.8920<br>Train Epoch: 139 Loss= 0.446267515 Accuracy= 0.8922<br>Train Epoch: 140 Loss= 0.445026428 Accuracy= 0.8930<br>Train Epoch: 141 Loss= 0.444738477 Accuracy= 0.8918<br>Train Epoch: 142 Loss= 0.443849623 Accuracy= 0.8916<br>Train Epoch: 143 Loss= 0.442687124 Accuracy= 0.8924<br>Train Epoch: 144 Loss= 0.442112952 Accuracy= 0.8924<br>Train Epoch: 145 Loss= 0.441391319 Accuracy= 0.8924<br>Train Epoch: 146 Loss= 0.440162748 Accuracy= 0.8926<br>Train Epoch: 147 Loss= 0.439293742 Accuracy= 0.8934<br>Train Epoch: 148 Loss= 0.438909620 Accuracy= 0.8930<br>Train Epoch: 149 Loss= 0.437819093 Accuracy= 0.8934<br>Train Epoch: 150 Loss= 0.437358975 Accuracy= 0.8934<br>Train Epoch: 151 Loss= 0.436241060 Accuracy= 0.8936<br>Train Epoch: 152 Loss= 0.436019480 Accuracy= 0.8940<br>Train Epoch: 153 Loss= 0.435418934 Accuracy= 0.8940<br>Train Epoch: 154 Loss= 0.434051841 Accuracy= 0.8948<br>Train Epoch: 155 Loss= 0.433334082 Accuracy= 0.8946<br>Train Epoch: 156 Loss= 0.432984859 Accuracy= 0.8944<br>Train Epoch: 157 Loss= 0.432401121 Accuracy= 0.8946<br>Train Epoch: 158 Loss= 0.431591660 Accuracy= 0.8944<br>Train Epoch: 159 Loss= 0.430783927 Accuracy= 0.8950<br>Train Epoch: 160 Loss= 0.430064738 Accuracy= 0.8954<br>Train Epoch: 161 Loss= 0.428908020 Accuracy= 0.8958<br>Train Epoch: 162 Loss= 0.428390443 Accuracy= 0.8956<br>Train Epoch: 163 Loss= 0.428132027 Accuracy= 0.8962<br>Train Epoch: 164 Loss= 0.427713633 Accuracy= 0.8958<br>Train Epoch: 165 Loss= 0.426613778 Accuracy= 0.8960<br>Train Epoch: 166 Loss= 0.425659865 Accuracy= 0.8964<br>Train Epoch: 167 Loss= 0.425214738 Accuracy= 0.8964<br>Train Epoch: 168 Loss= 0.424902737 Accuracy= 0.8960<br>Train Epoch: 169 Loss= 0.424074769 Accuracy= 0.8966<br>Train Epoch: 170 Loss= 0.423162699 Accuracy= 0.8974<br>Train Epoch: 171 Loss= 0.422749072 Accuracy= 0.8974<br>Train Epoch: 172 Loss= 0.422401696 Accuracy= 0.8964<br>Train Epoch: 173 Loss= 0.421341300 Accuracy= 0.8976<br>Train Epoch: 174 Loss= 0.420944721 Accuracy= 0.8964<br>Train Epoch: 175 Loss= 0.419966906 Accuracy= 0.8976<br>Train Epoch: 176 Loss= 0.419914395 Accuracy= 0.8968<br>Train Epoch: 177 Loss= 0.418810934 Accuracy= 0.8970<br>Train Epoch: 178 Loss= 0.418342829 Accuracy= 0.8968<br>Train Epoch: 179 Loss= 0.417744726 Accuracy= 0.8970<br>Train Epoch: 180 Loss= 0.417116791 Accuracy= 0.8978<br>Train Epoch: 181 Loss= 0.416599661 Accuracy= 0.8976<br>Train Epoch: 182 Loss= 0.415944725 Accuracy= 0.8982<br>Train Epoch: 183 Loss= 0.415637791 Accuracy= 0.8978<br>Train Epoch: 184 Loss= 0.414836079 Accuracy= 0.8980<br>Train Epoch: 185 Loss= 0.414405614 Accuracy= 0.8978<br>Train Epoch: 186 Loss= 0.413655072 Accuracy= 0.8982<br>Train Epoch: 187 Loss= 0.413016111 Accuracy= 0.8982<br>Train Epoch: 188 Loss= 0.412935942 Accuracy= 0.8988<br>Train Epoch: 189 Loss= 0.412001669 Accuracy= 0.8984<br>Train Epoch: 190 Loss= 0.411753237 Accuracy= 0.8992<br>Train Epoch: 191 Loss= 0.411443263 Accuracy= 0.8990<br>Train Epoch: 192 Loss= 0.410422057 Accuracy= 0.8984<br>Train Epoch: 193 Loss= 0.410251558 Accuracy= 0.8996<br>Train Epoch: 194 Loss= 0.409084409 Accuracy= 0.8988<br>Train Epoch: 195 Loss= 0.408952326 Accuracy= 0.8998<br>Train Epoch: 196 Loss= 0.408304602 Accuracy= 0.8998<br>Train Epoch: 197 Loss= 0.407955080 Accuracy= 0.8992<br>Train Epoch: 198 Loss= 0.407745570 Accuracy= 0.8992<br>Train Epoch: 199 Loss= 0.406976283 Accuracy= 0.8994<br>Train Epoch: 200 Loss= 0.406263798 Accuracy= 0.8996<br>Train Epoch: 201 Loss= 0.406233251 Accuracy= 0.8994<br>Train Epoch: 202 Loss= 0.405623794 Accuracy= 0.9000<br>Train Epoch: 203 Loss= 0.404749840 Accuracy= 0.8998<br>Train Epoch: 204 Loss= 0.404725671 Accuracy= 0.9006<br>Train Epoch: 205 Loss= 0.403718770 Accuracy= 0.9002<br>Train Epoch: 206 Loss= 0.403355181 Accuracy= 0.9006<br>Train Epoch: 207 Loss= 0.402798116 Accuracy= 0.9008<br>Train Epoch: 208 Loss= 0.402724475 Accuracy= 0.9002<br>Train Epoch: 209 Loss= 0.402527630 Accuracy= 0.9006<br>Train Epoch: 210 Loss= 0.401481658 Accuracy= 0.9006<br>Train Epoch: 211 Loss= 0.401139230 Accuracy= 0.9006<br>Train Epoch: 212 Loss= 0.400432110 Accuracy= 0.9004<br>Train Epoch: 213 Loss= 0.400378883 Accuracy= 0.9004<br>Train Epoch: 214 Loss= 0.399567872 Accuracy= 0.9002<br>Train Epoch: 215 Loss= 0.399531484 Accuracy= 0.9006<br>Train Epoch: 216 Loss= 0.399013489 Accuracy= 0.9008<br>Train Epoch: 217 Loss= 0.397973686 Accuracy= 0.9012<br>Train Epoch: 218 Loss= 0.397794008 Accuracy= 0.9008<br>Train Epoch: 219 Loss= 0.397283971 Accuracy= 0.9012<br>Train Epoch: 220 Loss= 0.397037268 Accuracy= 0.9014<br>Train Epoch: 221 Loss= 0.396341175 Accuracy= 0.9020<br>Train Epoch: 222 Loss= 0.396116793 Accuracy= 0.9002<br>Train Epoch: 223 Loss= 0.395749956 Accuracy= 0.9014<br>Train Epoch: 224 Loss= 0.395612061 Accuracy= 0.9008<br>Train Epoch: 225 Loss= 0.394687176 Accuracy= 0.9012<br>Train Epoch: 226 Loss= 0.394498616 Accuracy= 0.9016<br>Train Epoch: 227 Loss= 0.394306749 Accuracy= 0.9012<br>Train Epoch: 228 Loss= 0.393707484 Accuracy= 0.9008<br>Train Epoch: 229 Loss= 0.393643707 Accuracy= 0.9008<br>Train Epoch: 230 Loss= 0.393045634 Accuracy= 0.9008<br>Train Epoch: 231 Loss= 0.392508119 Accuracy= 0.9022<br>Train Epoch: 232 Loss= 0.391976804 Accuracy= 0.9018<br>Train Epoch: 233 Loss= 0.391808689 Accuracy= 0.9006<br>Train Epoch: 234 Loss= 0.391237199 Accuracy= 0.9014<br>Train Epoch: 235 Loss= 0.390866280 Accuracy= 0.9006<br>Train Epoch: 236 Loss= 0.390418172 Accuracy= 0.9010<br>Train Epoch: 237 Loss= 0.389898777 Accuracy= 0.9024<br>Train Epoch: 238 Loss= 0.389768124 Accuracy= 0.9020<br>Train Epoch: 239 Loss= 0.389144570 Accuracy= 0.9020<br>Train Epoch: 240 Loss= 0.389046282 Accuracy= 0.9030<br>Train Epoch: 241 Loss= 0.388572276 Accuracy= 0.9024<br>Train Epoch: 242 Loss= 0.388103604 Accuracy= 0.9018<br>Train Epoch: 243 Loss= 0.387917459 Accuracy= 0.9026<br>Train Epoch: 244 Loss= 0.387428015 Accuracy= 0.9024<br>Train Epoch: 245 Loss= 0.387170792 Accuracy= 0.9032<br>Train Epoch: 246 Loss= 0.386788905 Accuracy= 0.9014<br>Train Epoch: 247 Loss= 0.386517614 Accuracy= 0.9030<br>Train Epoch: 248 Loss= 0.386347741 Accuracy= 0.9020<br>Train Epoch: 249 Loss= 0.385344386 Accuracy= 0.9036<br>Train Epoch: 250 Loss= 0.384959489 Accuracy= 0.9026<br>Train Epoch: 251 Loss= 0.384517908 Accuracy= 0.9028<br>Train Epoch: 252 Loss= 0.384441257 Accuracy= 0.9030<br>Train Epoch: 253 Loss= 0.383821398 Accuracy= 0.9028<br>Train Epoch: 254 Loss= 0.383479148 Accuracy= 0.9022<br>Train Epoch: 255 Loss= 0.383624524 Accuracy= 0.9032<br>Train Epoch: 256 Loss= 0.383323073 Accuracy= 0.9022<br>Train Epoch: 257 Loss= 0.382732749 Accuracy= 0.9028<br>Train Epoch: 258 Loss= 0.382320166 Accuracy= 0.9030<br>Train Epoch: 259 Loss= 0.381811768 Accuracy= 0.9028<br>Train Epoch: 260 Loss= 0.381984144 Accuracy= 0.9026<br>Train Epoch: 261 Loss= 0.381227553 Accuracy= 0.9026<br>Train Epoch: 262 Loss= 0.380849212 Accuracy= 0.9022<br>Train Epoch: 263 Loss= 0.380524695 Accuracy= 0.9040<br>Train Epoch: 264 Loss= 0.380101144 Accuracy= 0.9028<br>Train Epoch: 265 Loss= 0.380186915 Accuracy= 0.9024<br>Train Epoch: 266 Loss= 0.379487067 Accuracy= 0.9030<br>Train Epoch: 267 Loss= 0.379631072 Accuracy= 0.9034<br>Train Epoch: 268 Loss= 0.378731072 Accuracy= 0.9034<br>Train Epoch: 269 Loss= 0.378665388 Accuracy= 0.9030<br>Train Epoch: 270 Loss= 0.378257990 Accuracy= 0.9032<br>Train Epoch: 271 Loss= 0.377845258 Accuracy= 0.9038<br>Train Epoch: 272 Loss= 0.377908498 Accuracy= 0.9034<br>Train Epoch: 273 Loss= 0.377575696 Accuracy= 0.9038<br>Train Epoch: 274 Loss= 0.377002954 Accuracy= 0.9034<br>Train Epoch: 275 Loss= 0.376586318 Accuracy= 0.9034<br>Train Epoch: 276 Loss= 0.376820147 Accuracy= 0.9040<br>Train Epoch: 277 Loss= 0.376379251 Accuracy= 0.9036<br>Train Epoch: 278 Loss= 0.375819713 Accuracy= 0.9036<br>Train Epoch: 279 Loss= 0.375545800 Accuracy= 0.9046<br>Train Epoch: 280 Loss= 0.375153273 Accuracy= 0.9044<br>Train Epoch: 281 Loss= 0.375212997 Accuracy= 0.9034<br>Train Epoch: 282 Loss= 0.374674737 Accuracy= 0.9042<br>Train Epoch: 283 Loss= 0.374336630 Accuracy= 0.9046<br>Train Epoch: 284 Loss= 0.373770863 Accuracy= 0.9042<br>Train Epoch: 285 Loss= 0.373896927 Accuracy= 0.9040<br>Train Epoch: 286 Loss= 0.373323888 Accuracy= 0.9046<br>Train Epoch: 287 Loss= 0.373260558 Accuracy= 0.9046<br>Train Epoch: 288 Loss= 0.372779518 Accuracy= 0.9044<br>Train Epoch: 289 Loss= 0.372727990 Accuracy= 0.9046<br>Train Epoch: 290 Loss= 0.372335255 Accuracy= 0.9046<br>Train Epoch: 291 Loss= 0.372065455 Accuracy= 0.9048<br>Train Epoch: 292 Loss= 0.371591061 Accuracy= 0.9046<br>Train Epoch: 293 Loss= 0.371365815 Accuracy= 0.9046<br>Train Epoch: 294 Loss= 0.371317178 Accuracy= 0.9048<br>Train Epoch: 295 Loss= 0.370640844 Accuracy= 0.9052<br>Train Epoch: 296 Loss= 0.370910048 Accuracy= 0.9044<br>Train Epoch: 297 Loss= 0.370179355 Accuracy= 0.9050<br>Train Epoch: 298 Loss= 0.370271593 Accuracy= 0.9054<br>Train Epoch: 299 Loss= 0.369908154 Accuracy= 0.9054<br>Train Epoch: 300 Loss= 0.369609326 Accuracy= 0.9054<br>Train Epoch: 301 Loss= 0.369176894 Accuracy= 0.9054<br>Train Epoch: 302 Loss= 0.369029045 Accuracy= 0.9056<br>Train Epoch: 303 Loss= 0.368548244 Accuracy= 0.9058<br>Train Epoch: 304 Loss= 0.368454874 Accuracy= 0.9058<br>Train Epoch: 305 Loss= 0.368041515 Accuracy= 0.9056<br>Train Epoch: 306 Loss= 0.367680520 Accuracy= 0.9058<br>Train Epoch: 307 Loss= 0.367845863 Accuracy= 0.9056<br>Train Epoch: 308 Loss= 0.367201656 Accuracy= 0.9060<br>Train Epoch: 309 Loss= 0.366869599 Accuracy= 0.9062<br>Train Epoch: 310 Loss= 0.366847694 Accuracy= 0.9060<br>Train Epoch: 311 Loss= 0.366336137 Accuracy= 0.9058<br>Train Epoch: 312 Loss= 0.366104513 Accuracy= 0.9060<br>Train Epoch: 313 Loss= 0.366278410 Accuracy= 0.9058<br>Train Epoch: 314 Loss= 0.365434617 Accuracy= 0.9064<br>Train Epoch: 315 Loss= 0.365378529 Accuracy= 0.9064<br>Train Epoch: 316 Loss= 0.365533412 Accuracy= 0.9058<br>Train Epoch: 317 Loss= 0.365197808 Accuracy= 0.9068<br>Train Epoch: 318 Loss= 0.365037024 Accuracy= 0.9068<br>Train Epoch: 319 Loss= 0.364381582 Accuracy= 0.9064<br>Train Epoch: 320 Loss= 0.364105165 Accuracy= 0.9072<br>Train Epoch: 321 Loss= 0.364401549 Accuracy= 0.9066<br>Train Epoch: 322 Loss= 0.363872409 Accuracy= 0.9066<br>Train Epoch: 323 Loss= 0.363355607 Accuracy= 0.9072<br>Train Epoch: 324 Loss= 0.363645494 Accuracy= 0.9064<br>Train Epoch: 325 Loss= 0.362869859 Accuracy= 0.9070<br>Train Epoch: 326 Loss= 0.362704009 Accuracy= 0.9066<br>Train Epoch: 327 Loss= 0.362510622 Accuracy= 0.9072<br>Train Epoch: 328 Loss= 0.362664402 Accuracy= 0.9064<br>Train Epoch: 329 Loss= 0.362214684 Accuracy= 0.9070<br>Train Epoch: 330 Loss= 0.361763179 Accuracy= 0.9068<br>Train Epoch: 331 Loss= 0.361724973 Accuracy= 0.9072<br>Train Epoch: 332 Loss= 0.361439168 Accuracy= 0.9072<br>Train Epoch: 333 Loss= 0.361238927 Accuracy= 0.9072<br>Train Epoch: 334 Loss= 0.360923618 Accuracy= 0.9070<br>Train Epoch: 335 Loss= 0.360640526 Accuracy= 0.9070<br>Train Epoch: 336 Loss= 0.360468805 Accuracy= 0.9074<br>Train Epoch: 337 Loss= 0.360336691 Accuracy= 0.9070<br>Train Epoch: 338 Loss= 0.360181004 Accuracy= 0.9066<br>Train Epoch: 339 Loss= 0.359589636 Accuracy= 0.9078<br>Train Epoch: 340 Loss= 0.359605044 Accuracy= 0.9074<br>Train Epoch: 341 Loss= 0.359191000 Accuracy= 0.9068<br>Train Epoch: 342 Loss= 0.359398872 Accuracy= 0.9072<br>Train Epoch: 343 Loss= 0.358821988 Accuracy= 0.9072<br>Train Epoch: 344 Loss= 0.358554870 Accuracy= 0.9072<br>Train Epoch: 345 Loss= 0.358417094 Accuracy= 0.9074<br>Train Epoch: 346 Loss= 0.358287454 Accuracy= 0.9082<br>Train Epoch: 347 Loss= 0.358403027 Accuracy= 0.9074<br>Train Epoch: 348 Loss= 0.357745498 Accuracy= 0.9076<br>Train Epoch: 349 Loss= 0.357700974 Accuracy= 0.9074<br>Train Epoch: 350 Loss= 0.357280284 Accuracy= 0.9074<br>Train Epoch: 351 Loss= 0.357116640 Accuracy= 0.9072<br>Train Epoch: 352 Loss= 0.356674671 Accuracy= 0.9076<br>Train Epoch: 353 Loss= 0.356743395 Accuracy= 0.9080<br>Train Epoch: 354 Loss= 0.356310487 Accuracy= 0.9080<br>Train Epoch: 355 Loss= 0.356106997 Accuracy= 0.9080<br>Train Epoch: 356 Loss= 0.356351852 Accuracy= 0.9076<br>Train Epoch: 357 Loss= 0.356079578 Accuracy= 0.9078<br>Train Epoch: 358 Loss= 0.355536312 Accuracy= 0.9080<br>Train Epoch: 359 Loss= 0.355534166 Accuracy= 0.9080<br>Train Epoch: 360 Loss= 0.355263025 Accuracy= 0.9070<br>Train Epoch: 361 Loss= 0.355054259 Accuracy= 0.9086<br>Train Epoch: 362 Loss= 0.354682177 Accuracy= 0.9086<br>Train Epoch: 363 Loss= 0.354584038 Accuracy= 0.9084<br>Train Epoch: 364 Loss= 0.354257971 Accuracy= 0.9076<br>Train Epoch: 365 Loss= 0.354202539 Accuracy= 0.9084<br>Train Epoch: 366 Loss= 0.354148418 Accuracy= 0.9080<br>Train Epoch: 367 Loss= 0.353945524 Accuracy= 0.9072<br>Train Epoch: 368 Loss= 0.353680283 Accuracy= 0.9084<br>Train Epoch: 369 Loss= 0.353619725 Accuracy= 0.9088<br>Train Epoch: 370 Loss= 0.353221059 Accuracy= 0.9086<br>Train Epoch: 371 Loss= 0.353100061 Accuracy= 0.9084<br>Train Epoch: 372 Loss= 0.352835447 Accuracy= 0.9090<br>Train Epoch: 373 Loss= 0.352596819 Accuracy= 0.9084<br>Train Epoch: 374 Loss= 0.352595180 Accuracy= 0.9080<br>Train Epoch: 375 Loss= 0.352259755 Accuracy= 0.9090<br>Train Epoch: 376 Loss= 0.352301449 Accuracy= 0.9086<br>Train Epoch: 377 Loss= 0.352147013 Accuracy= 0.9088<br>Train Epoch: 378 Loss= 0.351966113 Accuracy= 0.9088<br>Train Epoch: 379 Loss= 0.351528525 Accuracy= 0.9088<br>Train Epoch: 380 Loss= 0.351112694 Accuracy= 0.9088<br>Train Epoch: 381 Loss= 0.350878716 Accuracy= 0.9088<br>Train Epoch: 382 Loss= 0.351027966 Accuracy= 0.9094<br>Train Epoch: 383 Loss= 0.350885630 Accuracy= 0.9092<br>Train Epoch: 384 Loss= 0.350694865 Accuracy= 0.9086<br>Train Epoch: 385 Loss= 0.350394100 Accuracy= 0.9084<br>Train Epoch: 386 Loss= 0.349927545 Accuracy= 0.9090<br>Train Epoch: 387 Loss= 0.350075901 Accuracy= 0.9092<br>Train Epoch: 388 Loss= 0.349799097 Accuracy= 0.9086<br>Train Epoch: 389 Loss= 0.349439144 Accuracy= 0.9098<br>Train Epoch: 390 Loss= 0.349565566 Accuracy= 0.9100<br>Train Epoch: 391 Loss= 0.349208802 Accuracy= 0.9102<br>Train Epoch: 392 Loss= 0.349225044 Accuracy= 0.9100<br>Train Epoch: 393 Loss= 0.349022955 Accuracy= 0.9106<br>Train Epoch: 394 Loss= 0.348788708 Accuracy= 0.9090<br>Train Epoch: 395 Loss= 0.348476678 Accuracy= 0.9092<br>Train Epoch: 396 Loss= 0.348356456 Accuracy= 0.9096<br>Train Epoch: 397 Loss= 0.348270595 Accuracy= 0.9094<br>Train Epoch: 398 Loss= 0.348110557 Accuracy= 0.9100<br>Train Epoch: 399 Loss= 0.347774327 Accuracy= 0.9114<br>Train Epoch: 400 Loss= 0.347881585 Accuracy= 0.9108<br>Train Epoch: 401 Loss= 0.347597957 Accuracy= 0.9106<br>Train Epoch: 402 Loss= 0.347694665 Accuracy= 0.9110<br>Train Epoch: 403 Loss= 0.347311169 Accuracy= 0.9116<br>Train Epoch: 404 Loss= 0.347082287 Accuracy= 0.9106<br>Train Epoch: 405 Loss= 0.346681118 Accuracy= 0.9104<br>Train Epoch: 406 Loss= 0.346817166 Accuracy= 0.9100<br>Train Epoch: 407 Loss= 0.346650332 Accuracy= 0.9102<br>Train Epoch: 408 Loss= 0.346380711 Accuracy= 0.9116<br>Train Epoch: 409 Loss= 0.346278042 Accuracy= 0.9116<br>Train Epoch: 410 Loss= 0.346026599 Accuracy= 0.9106<br>Train Epoch: 411 Loss= 0.345805764 Accuracy= 0.9102<br>Train Epoch: 412 Loss= 0.345602989 Accuracy= 0.9100<br>Train Epoch: 413 Loss= 0.345262617 Accuracy= 0.9100<br>Train Epoch: 414 Loss= 0.345551938 Accuracy= 0.9114<br>Train Epoch: 415 Loss= 0.345476508 Accuracy= 0.9114<br>Train Epoch: 416 Loss= 0.345072389 Accuracy= 0.9110<br>Train Epoch: 417 Loss= 0.345159948 Accuracy= 0.9100<br>Train Epoch: 418 Loss= 0.344624996 Accuracy= 0.9112<br>Train Epoch: 419 Loss= 0.344826609 Accuracy= 0.9112<br>Train Epoch: 420 Loss= 0.344251603 Accuracy= 0.9098<br>Train Epoch: 421 Loss= 0.344352007 Accuracy= 0.9110<br>Train Epoch: 422 Loss= 0.344260216 Accuracy= 0.9110<br>Train Epoch: 423 Loss= 0.343791753 Accuracy= 0.9102<br>Train Epoch: 424 Loss= 0.343953133 Accuracy= 0.9108<br>Train Epoch: 425 Loss= 0.343585521 Accuracy= 0.9108<br>Train Epoch: 426 Loss= 0.343450099 Accuracy= 0.9106<br>Train Epoch: 427 Loss= 0.343184948 Accuracy= 0.9112<br>Train Epoch: 428 Loss= 0.343215674 Accuracy= 0.9110<br>Train Epoch: 429 Loss= 0.343070745 Accuracy= 0.9108<br>Train Epoch: 430 Loss= 0.342824966 Accuracy= 0.9110<br>Train Epoch: 431 Loss= 0.342438400 Accuracy= 0.9114<br>Train Epoch: 432 Loss= 0.342611969 Accuracy= 0.9114<br>Train Epoch: 433 Loss= 0.342214018 Accuracy= 0.9110<br>Train Epoch: 434 Loss= 0.342429280 Accuracy= 0.9108<br>Train Epoch: 435 Loss= 0.341949135 Accuracy= 0.9112<br>Train Epoch: 436 Loss= 0.342126906 Accuracy= 0.9110<br>Train Epoch: 437 Loss= 0.341858774 Accuracy= 0.9110<br>Train Epoch: 438 Loss= 0.341584474 Accuracy= 0.9110<br>Train Epoch: 439 Loss= 0.341345459 Accuracy= 0.9112<br>Train Epoch: 440 Loss= 0.341049880 Accuracy= 0.9120<br>Train Epoch: 441 Loss= 0.340980768 Accuracy= 0.9116<br>Train Epoch: 442 Loss= 0.340953112 Accuracy= 0.9114<br>Train Epoch: 443 Loss= 0.340954691 Accuracy= 0.9116<br>Train Epoch: 444 Loss= 0.340899229 Accuracy= 0.9110<br>Train Epoch: 445 Loss= 0.340938568 Accuracy= 0.9110<br>Train Epoch: 446 Loss= 0.341198325 Accuracy= 0.9110<br>Train Epoch: 447 Loss= 0.340240568 Accuracy= 0.9112<br>Train Epoch: 448 Loss= 0.340235293 Accuracy= 0.9112<br>Train Epoch: 449 Loss= 0.340209186 Accuracy= 0.9114<br>Train Epoch: 450 Loss= 0.339898020 Accuracy= 0.9116<br>Train Epoch: 451 Loss= 0.339793384 Accuracy= 0.9114<br>Train Epoch: 452 Loss= 0.339602858 Accuracy= 0.9120<br>Train Epoch: 453 Loss= 0.339292139 Accuracy= 0.9116<br>Train Epoch: 454 Loss= 0.339383274 Accuracy= 0.9120<br>Train Epoch: 455 Loss= 0.339096963 Accuracy= 0.9114<br>Train Epoch: 456 Loss= 0.339157701 Accuracy= 0.9114<br>Train Epoch: 457 Loss= 0.338972569 Accuracy= 0.9120<br>Train Epoch: 458 Loss= 0.338898569 Accuracy= 0.9118<br>Train Epoch: 459 Loss= 0.338588566 Accuracy= 0.9120<br>Train Epoch: 460 Loss= 0.338383496 Accuracy= 0.9116<br>Train Epoch: 461 Loss= 0.338389367 Accuracy= 0.9118<br>Train Epoch: 462 Loss= 0.338129699 Accuracy= 0.9120<br>Train Epoch: 463 Loss= 0.338002205 Accuracy= 0.9120<br>Train Epoch: 464 Loss= 0.337737024 Accuracy= 0.9118<br>Train Epoch: 465 Loss= 0.337787151 Accuracy= 0.9116<br>Train Epoch: 466 Loss= 0.337848932 Accuracy= 0.9118<br>Train Epoch: 467 Loss= 0.337492615 Accuracy= 0.9112<br>Train Epoch: 468 Loss= 0.337512612 Accuracy= 0.9120<br>Train Epoch: 469 Loss= 0.337134123 Accuracy= 0.9116<br>Train Epoch: 470 Loss= 0.336997300 Accuracy= 0.9118<br>Train Epoch: 471 Loss= 0.336745471 Accuracy= 0.9120<br>Train Epoch: 472 Loss= 0.337093860 Accuracy= 0.9124<br>Train Epoch: 473 Loss= 0.336436093 Accuracy= 0.9120<br>Train Epoch: 474 Loss= 0.336423337 Accuracy= 0.9116<br>Train Epoch: 475 Loss= 0.336435258 Accuracy= 0.9116<br>Train Epoch: 476 Loss= 0.336220562 Accuracy= 0.9120<br>Train Epoch: 477 Loss= 0.336083412 Accuracy= 0.9112<br>Train Epoch: 478 Loss= 0.336012244 Accuracy= 0.9116<br>Train Epoch: 479 Loss= 0.335907310 Accuracy= 0.9116<br>Train Epoch: 480 Loss= 0.336151212 Accuracy= 0.9126<br>Train Epoch: 481 Loss= 0.335842371 Accuracy= 0.9114<br>Train Epoch: 482 Loss= 0.335602969 Accuracy= 0.9126<br>Train Epoch: 483 Loss= 0.335610300 Accuracy= 0.9124<br>Train Epoch: 484 Loss= 0.335590661 Accuracy= 0.9120<br>Train Epoch: 485 Loss= 0.335201710 Accuracy= 0.9124<br>Train Epoch: 486 Loss= 0.334876269 Accuracy= 0.9124<br>Train Epoch: 487 Loss= 0.334915966 Accuracy= 0.9120<br>Train Epoch: 488 Loss= 0.335007548 Accuracy= 0.9124<br>Train Epoch: 489 Loss= 0.334643126 Accuracy= 0.9124<br>Train Epoch: 490 Loss= 0.334648579 Accuracy= 0.9124<br>Train Epoch: 491 Loss= 0.334624171 Accuracy= 0.9126<br>Train Epoch: 492 Loss= 0.334362388 Accuracy= 0.9134<br>Train Epoch: 493 Loss= 0.334085405 Accuracy= 0.9132<br>Train Epoch: 494 Loss= 0.333826602 Accuracy= 0.9128<br>Train Epoch: 495 Loss= 0.333956271 Accuracy= 0.9128<br>Train Epoch: 496 Loss= 0.334147930 Accuracy= 0.9126<br>Train Epoch: 497 Loss= 0.333745390 Accuracy= 0.9128<br>Train Epoch: 498 Loss= 0.333584398 Accuracy= 0.9130<br>Train Epoch: 499 Loss= 0.333650619 Accuracy= 0.9126<br>Train Epoch: 500 Loss= 0.333045900 Accuracy= 0.9126<br>Train Finshied!<br>Test Accurary: 0.9094</p>
 
    </div></div>
    </div><br><strong>学习效果极好：</strong><br><img src="/2022/01/12/machine-learning-5/pic1.png" alt="result_prediction"></p>
</div>
        </div>
        
            <div class="kratos-copyright text-center clearfix">
                <h5 itemprop="copyrightNotice">This work is licensed under <a rel="license nofollow" target="_blank" href="https://creativecommons.org/licenses/by-sa/4.0/">Attribution-ShareAlike 4.0 International (CC BY-SA 4.0)</a></h5>
            </div>
        
        <footer class="kratos-entry-footer clearfix">
            
                <div class="post-like-donate text-center clearfix" id="post-like-donate">
                
                
                    <a class="share" href="javascript:;"><i class="fa fa-share-alt"></i> Share</a>
                    <div class="share-wrap" style="display: none;">
    <div class="share-group">
        <a href="javascript:;" class="share-plain qq" onclick="share('qq');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-qq"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain qzone" onclick="share('qzone');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-star"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain weixin pop style-plain" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-weixin"></i>
            </div>
            <div class="share-int">
                <div class="qrcode" id="wechat-qr"></div>
                <p>打开微信“扫一扫”，打开网页后点击屏幕右上角分享按钮</p>
            </div>
        </a>
        <a href="javascript:;" class="share-plain weibo" onclick="share('weibo');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-weibo"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain facebook style-plain" onclick="share('facebook');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-facebook"></i>
            </div>
        </a>
        <a href="javascript:;" class="share-plain twitter style-plain" onclick="share('twitter');" rel="nofollow">
            <div class="icon-wrap">
                <i class="fa fa-twitter"></i>
            </div>
        </a>
    </div>
    <script type="text/javascript">
        $(()=>{
            new QRCode("wechat-qr", {
                text: "http://sunxinbin.cn/2022/01/12/machine-learning-5/",
                width: 150,
                height: 150,
                correctLevel : QRCode.CorrectLevel.H
            });
        });
        function share(dest) {
            const qqBase        = "https://connect.qq.com/widget/shareqq/index.html?";
            const weiboBase     = "https://service.weibo.com/share/share.php?";
            const qzoneBase     = "https://sns.qzone.qq.com/cgi-bin/qzshare/cgi_qzshare_onekey?";
            const facebookBase  = "https://www.facebook.com/sharer/sharer.php?";
            const twitterBase   = "https://twitter.com/intent/tweet?";
            const hostUrl       = "http://sunxinbin.cn/2022/01/12/machine-learning-5/";
            const title         = "「MINIST手写数字识别：分类应用入门」";
            const excerpt       = `用神经元处理分类问题`;
            let _URL;
            switch (dest) {
                case "qq"       : _URL = qqBase+"url="+hostUrl+"&title="+title+"&desc=&summary="+excerpt+"&site=cxpy";     break;
                case "weibo"    : _URL = weiboBase+"url="+hostUrl+"&title="+title+excerpt;                                 break;
                case "qzone"    : _URL = qzoneBase+"url="+hostUrl+"&title="+title+"&desc=&summary="+excerpt+"&site=cxpy";  break;
                case "facebook" : _URL = facebookBase+"u="+hostUrl;                                                        break;
                case "twitter"  : _URL = twitterBase+"text="+title+excerpt+"&url="+hostUrl;                                break;
            }
            window.open(_URL);
        };
    </script>
</div>
                
                </div>
            
            <div class="footer-tag clearfix">
                <div class="pull-left">
                <i class="fa fa-tags"></i>
                    <a class="tag-none-link" href="/tags/DL/" rel="tag">DL</a>
                </div>
                <div class="pull-date">
                    <time datetime="2023-03-30T11:26:48.945Z" itemprop="dateModified">Last modify：2023-03-30</time>
                </div>
            </div>
        </footer>
    </div>
    
        <nav class="navigation post-navigation clearfix" role="navigation">
            
            <div class="nav-previous clearfix">
                <a title=" 多元线性回归：波士顿房价预测问题" href="/2022/01/11/machine-learning-4/">&lt; older</a>
            </div>
            
            
            <div class="nav-next clearfix">
                <a title=" MINIST手写数字识别：多层神经网络与应用" href="/2022/01/13/machine-learning-6/">Newer &gt;</a>
            </div>
            
        </nav>
    
    
</article>

        

            </section>

        

                
            

<section id="kratos-widget-area" class="col-md-4 hidden-xs hidden-sm">
    <!-- 文章和页面根据splitter来分割，没有的话就从头开始设置为sticky -->
    
    
                <aside id="krw-about" class="widget widget-kratos-about clearfix">
    <div class="photo-background"></div>
    <div class="photo-wrapper clearfix">
        <div class="photo-wrapper-tip text-center">
            <img class="about-photo" src="/images/avatar.webp" loading="lazy" decoding="auto" />
        </div>
    </div>
    <div class="textwidget">
        <p class="text-center">Computer Science & Technology</p>
    </div>
    <div class="site-meta">
        <a class="meta-item" href="/archives/">
            <span class="title">
                Post
            </span>
            <span class="count">
                54
            </span>
        </a>
        <a class="meta-item" href="/categories/">
            <span class="title">
                Category
            </span>
            <span class="count">
                10
            </span>
        </a>
        <a class="meta-item" href="/tags/">
            <span class="title">
                Tag
            </span>
            <span class="count">
                20
            </span>
        </a>
    </div>
</aside>
            
                    <div class="sticky-area">
                
                    <aside id="krw-toc" class="widget widget-kratos-toc clearfix toc-div-class" >
    <div class="photo-background"></div>
    <h4 class="widget-title no-after">
        <i class="fa fa-compass"></i>
        Toc
        <span class="toc-progress-bar" role="progressbar" aria-label="阅读进度："></span>
    </h4>
    <div class="textwidget">
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#MNIST%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB%E9%97%AE%E9%A2%98"><span class="toc-text">MNIST手写数字识别问题</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98"><span class="toc-text">分类问题</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%BB%E5%8F%96%E6%96%B9%E6%B3%95"><span class="toc-text">数据集读取方法</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81"><span class="toc-text">独热编码</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E6%95%B0%E6%8D%AE%E9%9B%86%E5%88%92%E5%88%86"><span class="toc-text">数据集划分</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92"><span class="toc-text">逻辑回归</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%A4%9A%E5%85%83%E5%88%86%E7%B1%BB"><span class="toc-text">多元分类</span></a></li></ol></li></ol>
    </div>
</aside>
                
                
  <aside id="krw-categories" class="widget widget-kratos-categories clearfix">
    <h4 class="widget-title"><i class="fa fa-folder"></i>Categories List</h4>
      <ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Craniofacial-Registration/">Craniofacial Registration</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/DL/">DL</a><span class="category-list-count">12</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Feature-Point-Punctuation-Algorithm/">Feature Point Punctuation Algorithm</a><span class="category-list-count">4</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Git/">Git</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Literature/">Literature</a><span class="category-list-count">5</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/ML/">ML</a><span class="category-list-count">2</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Mathematical-Modeling/">Mathematical Modeling</a><span class="category-list-count">3</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Philosophy/">Philosophy</a><span class="category-list-count">1</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/Undergraduate-Courses/">Undergraduate Courses</a><span class="category-list-count">8</span></li><li class="category-list-item"><a class="category-list-link" href="/categories/%E8%93%9D%E6%A1%A5%E6%9D%AF/">蓝桥杯</a><span class="category-list-count">2</span></li></ul>
  </aside>


            
                
  <aside id="krw-tags" class="widget widget-kratos-tags clearfix">
    <h4 class="widget-title"><i class="fa fa-tags"></i>Tagcloud</h4>
      <div class="tag-clouds">
        <a href="/tags/Algorithm/" style="font-size: 0.6em;">Algorithm</a> <a href="/tags/Anecdote/" style="font-size: 0.6em;">Anecdote</a> <a href="/tags/CV/" style="font-size: 0.6em;">CV</a> <a href="/tags/Craniofacial-Registration/" style="font-size: 0.6em;">Craniofacial Registration</a> <a href="/tags/DL/" style="font-size: 0.8em;">DL</a> <a href="/tags/Emotion/" style="font-size: 0.68em;">Emotion</a> <a href="/tags/Feature-Point-Punctuation-Algorithm/" style="font-size: 0.72em;">Feature Point Punctuation Algorithm</a> <a href="/tags/Git/" style="font-size: 0.6em;">Git</a> <a href="/tags/Graduation-Design/" style="font-size: 0.6em;">Graduation Design</a> <a href="/tags/ICM/" style="font-size: 0.6em;">ICM</a> <a href="/tags/Latex/" style="font-size: 0.64em;">Latex</a> <a href="/tags/Literature/" style="font-size: 0.72em;">Literature</a> <a href="/tags/ML/" style="font-size: 0.68em;">ML</a> <a href="/tags/Mathematical-Modeling/" style="font-size: 0.64em;">Mathematical Modeling</a> <a href="/tags/OpenAI/" style="font-size: 0.6em;">OpenAI</a> <a href="/tags/Philosophy/" style="font-size: 0.6em;">Philosophy</a> <a href="/tags/Python/" style="font-size: 0.6em;">Python</a> <a href="/tags/Undergraduate-Courses/" style="font-size: 0.76em;">Undergraduate Courses</a>
      </div>
  </aside>

            
                
  <aside id="krw-posts" class="widget widget-kratos-posts">
  <h4 class="widget-title"><i class="fa fa-file"></i>Recent posts</h4>
  <div class="tab-content">
      <ul class="list-group">
        
        
          
          
            <a class="list-group-item" href="/2024/02/28/2D-to-3D/"><i class="fa  fa-book"></i> 面向3D模型生成</a>
            
          
        
          
          
            <a class="list-group-item" href="/2023/12/27/graduation-design/"><i class="fa  fa-book"></i> Graduation Design</a>
            
          
        
          
          
            <a class="list-group-item" href="/2023/06/21/Compilation-principle/"><i class="fa  fa-book"></i> Compilation Principle</a>
            
          
        
          
          
            <a class="list-group-item" href="/2023/06/18/distributed-system/"><i class="fa  fa-book"></i> Distributed System</a>
            
          
        
          
          
            <a class="list-group-item" href="/2023/06/15/software-engineering/"><i class="fa  fa-book"></i> Software Engineering Review</a>
            
          
        
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
          
            
      </ul>
  </div>
  </aside>

            
    </div>
</section>
        
        </div>
    </div>
</div>
<footer>
    <div id="footer"  >
        <div class="container">
            <div class="row">
                <div class="col-md-6 col-md-offset-3 footer-list text-center">
                    <ul class="kratos-social-icons">
                        
                        <li><a href="mailto:2332431354@qq.com"><i class="fa fa-envelope"></i></a></li>
                        
                        
                        
                        
                        <li><a target="_blank" rel="me" href="https:///@SunXinbin"><i class="fa fa fa-share-alt-square"></i></a></li>
                        <li><a target="_blank" rel="nofollow" href="https://github.com/xinbinsun"><i class="fa fa-github"></i></a></li>
                        
                    </ul>
                    <ul class="kratos-copyright">
                        <div>
                            <li>&copy; 2024 Neo Sun Copyright.</li>
                            <li>本站已运行<span id="span_dt">Loading...</span></li>
                        </div>
                        <div>
                            <li>Theme <a href="https://github.com/Candinya/Kratos-Rebirth" target="_blank">Kratos:Rebirth</a></li>
                            <li>Site built with&nbsp;<i class="fa fa-heart throb" style="color:#d43f57"></i>&nbsp;by 孙新斌.</li>
                        </div>
                        <div>
                            <li>Powered by <a href="https://hexo.io" target="_blank" rel="nofollow">Hexo</a></li>
                            <li>Hosted on <a href="https://github.io" target="_blank">Github Pages</a></li>
                        </div>
                        <div>
                            <li><a href="https://beian.miit.gov.cn" rel="external nofollow" target="_blank">鲁ICP备23010101号</a></li>
                            <li><a href="http://www.beian.gov.cn" rel="external nofollow" target="_blank"><img src="/images/psr.webp" width="12" height="12" loading="lazy" decoding="auto" />鲁公网安备371402000348</a></li>
                        </div>
                    </ul>
                </div>
            </div>
        </div>
        <div class="kr-tool text-center">
            <div class="tool">
                
                    <div class="box search-box">
                        <a href="/search/">
                            <span class="fa fa-search"></span>
                        </a>
                    </div>
                
                
                    <div class="box theme-box" id="darkmode-switch">
                        <span class="fa fa-adjust"></span>
                    </div>
                
                
                
            </div>
            <div class="box gotop-box">
                <span class="fa fa-chevron-up"></span>
            </div>
        </div>
    </div>
</footer>
</div>
</div>

        <script defer src="/vendors/bootstrap@3.3.4/dist/js/bootstrap.min.js"></script>
<script defer src="/vendors/nprogress@0.2.0/nprogress.js"></script>
<script>
    if (!window.kr) {
        window.kr = {};
    }
    window.kr.notMobile = (!(navigator.userAgent.match(/(phone|pad|pod|iPhone|iPod|ios|iPad|Android|Mobile|BlackBerry|IEMobile|MQQBrowser|JUC|Fennec|wOSBrowser|BrowserNG|WebOS|Symbian|Windows Phone)/i)));
    window.kr.siteRoot = "/";
</script>


    <script async src="/js/candy.min.js"></script>




    <script defer src="/vendors/@fancyapps/fancybox@3.5.7/dist/jquery.fancybox.min.js"></script>

<script defer src="/js/kratosr.min.js"></script>
<script defer src="/js/pjax.min.js"></script>



<!-- Extra support for third-party plguins  -->


    </body>
</html>